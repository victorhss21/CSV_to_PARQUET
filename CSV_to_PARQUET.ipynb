{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Objetivo:**\n",
    "\n",
    "Scritp python que transforma um arquivo CSV (preferencialmente, grande) para um arquivo do tipo PARQUET\n",
    "\n",
    "### **Ganhos:**\n",
    "\n",
    "O arquivo parquet é mais leve e rápido, tanto leitura, operações nos dados e escrita."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versão - Programação Procedural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**01)** Importa bibliotecas necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import de bibliotecas\n",
    "import pandas as pd\n",
    "import os\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**02)** Define nome do arquivo CSV a ser transformado em Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina o caminho do arquivo CSV\n",
    "csv_file = 'Rate\\Rate.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**03)** Carrega o arquivo CSV e salva chunks intermediário em parquet em um diretório temporário:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_0.parquet\n",
      "Chunk 1 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_1.parquet\n",
      "Chunk 2 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_2.parquet\n",
      "Chunk 3 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_3.parquet\n",
      "Chunk 4 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_4.parquet\n",
      "Chunk 5 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_5.parquet\n",
      "Chunk 6 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_6.parquet\n",
      "Chunk 7 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_7.parquet\n",
      "Chunk 8 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_8.parquet\n",
      "Chunk 9 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_9.parquet\n",
      "Chunk 10 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_10.parquet\n",
      "Chunk 11 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_11.parquet\n",
      "Chunk 12 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_12.parquet\n",
      "Chunk 13 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_13.parquet\n",
      "Chunk 14 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_14.parquet\n",
      "Chunk 15 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_15.parquet\n",
      "Chunk 16 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_16.parquet\n",
      "Chunk 17 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_17.parquet\n",
      "Chunk 18 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_18.parquet\n",
      "Chunk 19 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_19.parquet\n",
      "Chunk 20 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_20.parquet\n",
      "Chunk 21 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_21.parquet\n",
      "Chunk 22 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_22.parquet\n",
      "Chunk 23 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_23.parquet\n",
      "Chunk 24 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_24.parquet\n",
      "Chunk 25 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_25.parquet\n",
      "Chunk 26 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_26.parquet\n",
      "Chunk 27 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_27.parquet\n",
      "Chunk 28 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_28.parquet\n",
      "Chunk 29 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_29.parquet\n",
      "Chunk 30 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_30.parquet\n",
      "Chunk 31 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_31.parquet\n",
      "Chunk 32 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_32.parquet\n",
      "Chunk 33 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_33.parquet\n",
      "Chunk 34 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_34.parquet\n",
      "Chunk 35 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_35.parquet\n",
      "Chunk 36 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_36.parquet\n",
      "Chunk 37 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_37.parquet\n",
      "Chunk 38 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_38.parquet\n",
      "Chunk 39 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_39.parquet\n",
      "Chunk 40 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_40.parquet\n",
      "Chunk 41 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_41.parquet\n",
      "Chunk 42 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_42.parquet\n",
      "Chunk 43 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_43.parquet\n",
      "Chunk 44 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_44.parquet\n",
      "Chunk 45 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_45.parquet\n",
      "Chunk 46 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_46.parquet\n",
      "Chunk 47 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_47.parquet\n",
      "Chunk 48 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_48.parquet\n",
      "Chunk 49 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_49.parquet\n",
      "Chunk 50 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_50.parquet\n",
      "Chunk 51 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_51.parquet\n",
      "Chunk 52 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_52.parquet\n",
      "Chunk 53 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_53.parquet\n",
      "Chunk 54 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_54.parquet\n",
      "Chunk 55 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_55.parquet\n",
      "Chunk 56 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_56.parquet\n",
      "Chunk 57 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_57.parquet\n",
      "Chunk 58 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_58.parquet\n",
      "Chunk 59 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_59.parquet\n",
      "Chunk 60 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_60.parquet\n",
      "Chunk 61 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_61.parquet\n",
      "Chunk 62 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_62.parquet\n",
      "Chunk 63 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_63.parquet\n",
      "Chunk 64 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_64.parquet\n",
      "Chunk 65 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_65.parquet\n",
      "Chunk 66 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_66.parquet\n",
      "Chunk 67 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_67.parquet\n",
      "Chunk 68 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_68.parquet\n",
      "Chunk 69 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_69.parquet\n",
      "Chunk 70 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_70.parquet\n",
      "Chunk 71 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_71.parquet\n",
      "Chunk 72 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_72.parquet\n",
      "Chunk 73 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_73.parquet\n",
      "Chunk 74 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_74.parquet\n",
      "Chunk 75 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_75.parquet\n",
      "Chunk 76 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_76.parquet\n",
      "Chunk 77 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_77.parquet\n",
      "Chunk 78 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_78.parquet\n",
      "Chunk 79 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_79.parquet\n",
      "Chunk 80 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_80.parquet\n",
      "Chunk 81 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_81.parquet\n",
      "Chunk 82 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_82.parquet\n",
      "Chunk 83 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_83.parquet\n",
      "Chunk 84 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_84.parquet\n",
      "Chunk 85 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_85.parquet\n",
      "Chunk 86 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_86.parquet\n",
      "Chunk 87 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_87.parquet\n",
      "Chunk 88 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_88.parquet\n",
      "Chunk 89 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_89.parquet\n",
      "Chunk 90 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_90.parquet\n",
      "Chunk 91 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_91.parquet\n",
      "Chunk 92 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_92.parquet\n",
      "Chunk 93 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_93.parquet\n",
      "Chunk 94 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_94.parquet\n",
      "Chunk 95 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_95.parquet\n",
      "Chunk 96 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_96.parquet\n",
      "Chunk 97 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_97.parquet\n",
      "Chunk 98 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_98.parquet\n",
      "Chunk 99 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_99.parquet\n",
      "Chunk 100 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_100.parquet\n",
      "Chunk 101 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_101.parquet\n",
      "Chunk 102 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_102.parquet\n",
      "Chunk 103 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_103.parquet\n",
      "Chunk 104 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_104.parquet\n",
      "Chunk 105 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_105.parquet\n",
      "Chunk 106 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_106.parquet\n",
      "Chunk 107 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_107.parquet\n",
      "Chunk 108 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_108.parquet\n",
      "Chunk 109 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_109.parquet\n",
      "Chunk 110 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_110.parquet\n",
      "Chunk 111 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_111.parquet\n",
      "Chunk 112 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_112.parquet\n",
      "Chunk 113 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_113.parquet\n",
      "Chunk 114 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_114.parquet\n",
      "Chunk 115 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_115.parquet\n",
      "Chunk 116 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_116.parquet\n",
      "Chunk 117 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_117.parquet\n",
      "Chunk 118 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_118.parquet\n",
      "Chunk 119 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_119.parquet\n",
      "Chunk 120 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_120.parquet\n",
      "Chunk 121 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_121.parquet\n",
      "Chunk 122 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_122.parquet\n",
      "Chunk 123 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_123.parquet\n",
      "Chunk 124 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_124.parquet\n",
      "Chunk 125 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_125.parquet\n",
      "Chunk 126 salvo como arquivos_parquet_temp\\arquivo_parquet_parte_126.parquet\n",
      "Arquivo CSV foi dividido e convertido para Parquet com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Defina o diretório onde os arquivos Parquet serão salvos\n",
    "output_dir = 'arquivos_parquet_temp'\n",
    "\n",
    "# Crie o diretório se ele não existir\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Defina o tamanho do chunk (número de linhas por chunk)\n",
    "chunk_size = 100000  # Ajuste conforme necessário\n",
    "\n",
    "# Leitura e processamento por chunks\n",
    "for i, chunk in enumerate(pd.read_csv(csv_file, chunksize=chunk_size)):\n",
    "    # Define o nome do arquivo Parquet para cada chunk\n",
    "    chunk_parquet_file = os.path.join(output_dir, f'arquivo_parquet_parte_{i}.parquet')\n",
    "    \n",
    "    # Salva cada chunk como um arquivo Parquet separado no diretório especificado\n",
    "    chunk.to_parquet(chunk_parquet_file, engine='pyarrow', index=False)\n",
    "    \n",
    "    print(f\"Chunk {i} salvo como {chunk_parquet_file}\")\n",
    "\n",
    "print(\"Arquivo CSV foi dividido e convertido para Parquet com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**04)** consolida arquivos intermediários parquet em um arquivo final:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos os arquivos Parquet foram combinados e salvos como arquivo_combinado.parquet\n",
      "O diretório arquivos_parquet_temp foi removido com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Diretório onde os arquivos Parquet temporários estão localizados\n",
    "parquet_folder = output_dir  # O diretório onde os arquivos Parquet foram salvos\n",
    "\n",
    "# Verifique se o diretório existe\n",
    "if not os.path.exists(parquet_folder):\n",
    "    raise Exception(f\"O diretório {parquet_folder} não existe.\")\n",
    "\n",
    "# Lista de arquivos Parquet que você deseja combinar\n",
    "parquet_files = [f for f in os.listdir(parquet_folder) if f.endswith('.parquet')]\n",
    "\n",
    "# Verifique se há arquivos Parquet no diretório\n",
    "if not parquet_files:\n",
    "    raise Exception(f\"Nenhum arquivo Parquet encontrado no diretório {parquet_folder}.\")\n",
    "\n",
    "# Lista para armazenar as tabelas PyArrow de cada arquivo Parquet\n",
    "parquet_tables = []\n",
    "\n",
    "# Ler cada arquivo Parquet e armazenar a tabela na lista\n",
    "for file in parquet_files:\n",
    "    file_path = os.path.join(parquet_folder, file)\n",
    "    table = pq.read_table(file_path)\n",
    "    parquet_tables.append(table)\n",
    "\n",
    "# Combinar todas as tabelas em uma única tabela\n",
    "combined_table = pa.concat_tables(parquet_tables)\n",
    "\n",
    "# Definir o caminho do arquivo Parquet combinado\n",
    "output_file = 'dataset.parquet'\n",
    "\n",
    "# Salvar a tabela combinada em um único arquivo Parquet\n",
    "pq.write_table(combined_table, output_file)\n",
    "\n",
    "print(f\"Todos os arquivos Parquet foram combinados e salvos como {output_file}\")\n",
    "\n",
    "# Apagar o diretório intermediário e seus arquivos\n",
    "try:\n",
    "    shutil.rmtree(parquet_folder)\n",
    "    print(f\"O diretório {parquet_folder} foi removido com sucesso.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao remover o diretório {parquet_folder}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versão - Programação Orientada a Objeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação do tqdm para geração da barra de progresso simples (verbosidade de saída comprimida)\n",
    "!pip install tqdm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instabal biblioteca necessárias\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm  # Biblioteca para a barra de progresso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classe e atributos\n",
    "class ParquetProcessor:\n",
    "    def __init__(self, csv_file, output_parquet, temp_dir='arquivos_parquet_temp', chunk_size=100000):\n",
    "        \"\"\"\n",
    "        Inicializa o processador Parquet.\n",
    "        \n",
    "        :param csv_file: Caminho do arquivo CSV de entrada.\n",
    "        :param output_parquet: Caminho do arquivo Parquet final.\n",
    "        :param temp_dir: Diretório para armazenar os arquivos Parquet temporários.\n",
    "        :param chunk_size: Número de linhas por chunk ao ler o CSV.\n",
    "        \"\"\"\n",
    "        self.csv_file = csv_file\n",
    "        self.output_parquet = output_parquet\n",
    "        self.temp_dir = temp_dir\n",
    "        self.chunk_size = chunk_size\n",
    "\n",
    "    def create_parquet_chunks(self):\n",
    "        \"\"\"Lê o arquivo CSV em chunks e salva os chunks como arquivos Parquet temporários.\"\"\"\n",
    "        # Criar o diretório temporário, se não existir\n",
    "        if not os.path.exists(self.temp_dir):\n",
    "            os.makedirs(self.temp_dir)\n",
    "\n",
    "        # Verificar a quantidade total de linhas no arquivo CSV para mostrar o progresso\n",
    "        total_rows = sum(1 for _ in open(self.csv_file)) - 1  # Menos o cabeçalho\n",
    "\n",
    "        # Processar o CSV em chunks e salvar como arquivos Parquet\n",
    "        with tqdm(total=total_rows, desc=\"Criando arquivos Parquet\", unit=\" linhas\") as pbar:\n",
    "            for i, chunk in enumerate(pd.read_csv(self.csv_file, chunksize=self.chunk_size)):\n",
    "                chunk_parquet_file = os.path.join(self.temp_dir, f'arquivo_parquet_parte_{i}.parquet')\n",
    "                \n",
    "                # Salvar chunk como arquivo Parquet\n",
    "                chunk.to_parquet(chunk_parquet_file, engine='pyarrow', index=False)\n",
    "\n",
    "                # Atualizar a barra de progresso com o número de linhas processadas\n",
    "                pbar.update(len(chunk))  # Atualiza a barra com o tamanho do chunk\n",
    "\n",
    "    def combine_parquet_files(self):\n",
    "        \"\"\"Combina os arquivos Parquet temporários em um único arquivo Parquet final.\"\"\"\n",
    "        # Verificar se o diretório de arquivos temporários existe\n",
    "        if not os.path.exists(self.temp_dir):\n",
    "            raise Exception(f\"O diretório {self.temp_dir} não existe.\")\n",
    "\n",
    "        # Listar os arquivos Parquet no diretório temporário\n",
    "        parquet_files = [f for f in os.listdir(self.temp_dir) if f.endswith('.parquet')]\n",
    "\n",
    "        # Verificar se há arquivos Parquet no diretório\n",
    "        if not parquet_files:\n",
    "            raise Exception(f\"Nenhum arquivo Parquet encontrado no diretório {self.temp_dir}.\")\n",
    "\n",
    "        # Combinar todos os arquivos Parquet em uma única tabela\n",
    "        parquet_tables = []\n",
    "        for file in parquet_files:\n",
    "            file_path = os.path.join(self.temp_dir, file)\n",
    "            table = pq.read_table(file_path)\n",
    "            parquet_tables.append(table)\n",
    "\n",
    "        combined_table = pa.concat_tables(parquet_tables)\n",
    "\n",
    "        # Salvar a tabela combinada em um único arquivo Parquet\n",
    "        pq.write_table(combined_table, self.output_parquet)\n",
    "        print(f\"Arquivo Parquet combinado salvo como {self.output_parquet}\")\n",
    "\n",
    "    def clean_up(self):\n",
    "        \"\"\"Remove o diretório temporário após a consolidação dos arquivos.\"\"\"\n",
    "        try:\n",
    "            shutil.rmtree(self.temp_dir)\n",
    "            print(f\"O diretório {self.temp_dir} foi removido com sucesso.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao remover o diretório {self.temp_dir}: {e}\")\n",
    "\n",
    "    def process(self, remove_temp=True):\n",
    "        \"\"\"\n",
    "        Executa o processamento completo: leitura do CSV, criação dos chunks Parquet e consolidação final.\n",
    "        \n",
    "        :param remove_temp: Define se o diretório temporário deve ser removido após a consolidação.\n",
    "        \"\"\"\n",
    "        print(\"Iniciando a criação dos chunks Parquet...\")\n",
    "        self.create_parquet_chunks()\n",
    "\n",
    "        print(\"Iniciando a consolidação dos arquivos Parquet...\")\n",
    "        self.combine_parquet_files()\n",
    "\n",
    "        if remove_temp:\n",
    "            print(\"Removendo o diretório temporário...\")\n",
    "            self.clean_up()\n",
    "\n",
    "        print(\"Processamento completo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a criação dos chunks Parquet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Criando arquivos Parquet: 100%|██████████| 12694445/12694445 [00:45<00:00, 278449.78 linhas/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a consolidação dos arquivos Parquet...\n",
      "Arquivo Parquet combinado salvo como dataset.parquet\n",
      "Removendo o diretório temporário...\n",
      "O diretório arquivos_parquet_temp foi removido com sucesso.\n",
      "Processamento completo!\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de uso:\n",
    "if __name__ == '__main__':\n",
    "    # Caminho do arquivo CSV de entrada\n",
    "    csv_file = 'Rate\\Rate.csv'\n",
    "\n",
    "    # Caminho do arquivo Parquet final\n",
    "    output_parquet = 'dataset.parquet'\n",
    "\n",
    "    # Instanciar o processador Parquet\n",
    "    processor = ParquetProcessor(csv_file, output_parquet, chunk_size=1000000)\n",
    "\n",
    "    # Executar o processamento\n",
    "    processor.process(remove_temp=True)  # Define se o diretório intermediário deve ser removido ou não"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
